# OpenNebula Helm Chart Values
# See: https://github.com/pablodelarco/opennebula-helm

## Image configuration
image:
  repository: pablodelarco/opennebula
  tag: "latest"
  pullPolicy: IfNotPresent

## OpenNebula settings
opennebula:
  ## Admin password for oneadmin user
  ## Default: opennebula (override in production!)
  adminPassword: "opennebula"

## MariaDB subchart configuration
## ref: https://github.com/bitnami/charts/tree/main/bitnami/mariadb
mariadb:
  enabled: true
  architecture: standalone
  auth:
    database: opennebula
    username: oneadmin
    ## Password is auto-generated if not set
    # password: ""
  primary:
    persistence:
      enabled: true
      size: 8Gi

## External database configuration (when mariadb.enabled=false)
## Required fields when using external database
externalDatabase:
  host: ""
  port: 3306
  database: opennebula
  username: oneadmin
  ## Password for external database
  password: ""
  ## Or use existing secret (takes precedence over password)
  ## Secret must contain key 'mariadb-password'
  existingSecret: ""

## Persistence for OpenNebula data (/var/lib/one)
persistence:
  enabled: true
  size: 20Gi
  ## storageClass: ""  # Use cluster default
  accessMode: ReadWriteOnce

## Service configuration
service:
  type: ClusterIP
  ## Ports exposed
  ## oned: 2633, sunstone: 9869, fireedge: 2616
  ## oneflow: 2474, onegate: 5030

## FireEdge proxy configuration (handles __HOST__ replacement)
## Enabled by default - required for web UI to work correctly
fireedgeProxy:
  enabled: true

  ## Optional: Override auto-detected public URL
  ## Leave empty for auto-detection (recommended)
  ## Set only if you need a specific URL different from how users access it
  publicURL: ""

  ## Nginx image for sidecar
  image:
    repository: nginx
    tag: "1.27-alpine"

  ## Resources for nginx sidecar (lightweight)
  resources:
    limits:
      cpu: 100m
      memory: 64Mi
    requests:
      cpu: 10m
      memory: 16Mi

## Ingress configuration for FireEdge web UI
ingress:
  enabled: false
  className: ""
  annotations: {}
  hostname: opennebula.local
  ## TLS configuration
  tls:
    enabled: false
    secretName: ""  # Name of TLS secret

## SSH keys for hypervisor communication
## If not provided, keys will be generated and stored in a persistent secret
ssh:
  ## Provide existing keys (base64 encoded)
  # privateKey: ""
  # publicKey: ""

## Resource limits and requests
## No defaults - set based on your environment
resources: {}
  # limits:
  #   cpu: 2
  #   memory: 4Gi
  # requests:
  #   cpu: 500m
  #   memory: 1Gi

## Pod security context
podSecurityContext: {}

## Container security context
securityContext: {}

## Node selector
nodeSelector: {}

## Tolerations
tolerations: []

## Affinity
affinity: {}

## ============================================================
## ONEDEPLOY INTEGRATION - Hypervisor Node Provisioning
## ============================================================
## This section mirrors the OneDeploy inventory format
## Users familiar with OneDeploy can use the same configuration
## Ref: https://github.com/OpenNebula/one-deploy

onedeploy:
  ## Enable automatic provisioning of hypervisor nodes
  ## When enabled, a Kubernetes Job will provision the specified hosts
  enabled: false

  ## --------------------------------------------------------
  ## Global Variables (maps to all.vars in OneDeploy)
  ## --------------------------------------------------------
  vars:
    ## SSH user for connecting to nodes (must have sudo/root access)
    ansible_user: root

    ## OpenNebula version to install on nodes
    one_version: "7.0"

    ## Ensure hosts are registered with OpenNebula after provisioning
    ensure_hosts: true

    ## --------------------------------------------------------
    ## Virtual Networks (maps to vn in OneDeploy)
    ## Define networks that will be created in OpenNebula
    ## --------------------------------------------------------
    vn: {}
      ## Example virtual network configuration:
      # admin_net:
      #   managed: true
      #   template:
      #     VN_MAD: bridge
      #     PHYDEV: eth0
      #     BRIDGE: br0
      #     AR:
      #       TYPE: IP4
      #       IP: 172.20.0.100
      #       SIZE: 48
      #     NETWORK_ADDRESS: 172.20.0.0
      #     NETWORK_MASK: 255.255.255.0
      #     GATEWAY: 172.20.0.1
      #     DNS: 1.1.1.1

    ## --------------------------------------------------------
    ## Datastores (maps to ds in OneDeploy)
    ## --------------------------------------------------------
    ds:
      ## Mode: ssh (local storage), shared (NFS), or ceph
      mode: ssh
      ## For shared mode, configure mounts:
      # config:
      #   mounts:
      #     - type: system
      #       path: /mnt/datastores/0
      #     - type: image
      #       path: /mnt/datastores/1

    ## --------------------------------------------------------
    ## NFS Mounts (maps to fstab in OneDeploy)
    ## Only needed for shared storage mode
    ## --------------------------------------------------------
    fstab: []
      ## Example NFS mount:
      # - src: "nfs-server:/var/lib/one/datastores"
      #   path: /mnt/datastores

    ## --------------------------------------------------------
    ## Optional Features
    ## --------------------------------------------------------
    features:
      prometheus: false
      ceph: false

  ## --------------------------------------------------------
  ## Hypervisor Nodes (maps to node.hosts in OneDeploy)
  ## Define the hosts that will be provisioned as hypervisors
  ## --------------------------------------------------------
  node:
    hosts: {}
      ## Example node configuration:
      # kvm-node-01:
      #   ansible_host: 192.168.1.101
      #   # virtualization: kvm  # default
      # kvm-node-02:
      #   ansible_host: 192.168.1.102
      # lxc-node-01:
      #   ansible_host: 192.168.1.103
      #   virtualization: lxc  # Override for LXC containers

  ## --------------------------------------------------------
  ## Provisioner Configuration (Helm-specific settings)
  ## --------------------------------------------------------
  provisioner:
    ## Docker image for the provisioner
    image:
      repository: pablodelarco/opennebula-provisioner
      tag: "latest"
      pullPolicy: IfNotPresent

    ## SSH configuration for connecting to hosts
    ssh:
      ## Private key for SSH access to nodes (base64 encoded)
      ## Generate: ssh-keygen -t ed25519 -f provisioner_key -N ""
      ## Encode: cat provisioner_key | base64 -w0
      privateKey: ""

      ## Or use an existing Kubernetes secret containing the SSH key
      ## Secret must have key 'id_rsa' with the private key
      existingSecret: ""

    ## Job configuration
    backoffLimit: 3
    ttlSecondsAfterFinished: 3600  # Clean up job after 1 hour

    ## Resources for the provisioner job
    resources:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
